{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e16155e-d194-4b24-a9f3-3d1d6d4693ef",
   "metadata": {},
   "source": [
    "# Self Attention - Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4787ffc8-ac76-460b-9ce5-e46e2d4c5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93019565",
   "metadata": {},
   "source": [
    "This is how attetion is described in the [Attention is All You Need](https://arxiv.org/abs/1706.03762) paper. <br>\n",
    "\n",
    "\"An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key.\"\n",
    "\n",
    "-- Attention Is All You Need, Vaswani et. al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a78ad",
   "metadata": {},
   "source": [
    "$Attention(Q,K,V) = softmax( \\frac{QK^{T}} {\\sqrt{d_{k}}} )V$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa789f0d",
   "metadata": {},
   "source": [
    "Let's suppose that we have a sentence of three words. For example 'sky is blue'. Let's  also assume that these three words are represented using three numbers, 1, 2 and 3. These are called tokens.  Therefore, our sequence of tokens is given by the following tensor. Tokenization is the process of breaking a sequence of characters into different parts. There are many tokenization methods. What I have done here is a very simple tokenization method for the sake of easliy explaining the concepts of the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf8ce180",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence =  torch.tensor([[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98d136b9-b6db-42ad-96c2-6f84d126b63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ddbac1-815c-4c83-89cf-24acc5987ca5",
   "metadata": {},
   "source": [
    "In this case, our `sequence length` is 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b6ca82-e4c7-427b-8404-3c07e0505499",
   "metadata": {},
   "source": [
    "Tokenization alone is not enough to create a information-rich representation of a character sequence. We will have to come up with a vector representation for each token. These are called embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6550cb4-55d0-431d-99e0-9de98804f477",
   "metadata": {},
   "source": [
    "let's assume that the embedding vectors of 1,2 and 3 are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dddf9ce-6d6e-49f6-b9ba-4f18469ede60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [-1.072, -0.5001], 2: [-0.002, -0.4311], 3: [-0.002, -0.4311]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = {1: [-1.0720, -0.5001], 2:  [-0.0020, -0.4311], 3: [-0.0020, -0.4311]}\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad64433-e455-4d5f-b778-b65e16bcd062",
   "metadata": {},
   "source": [
    "Therefore, our embedded tokens are,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0e9092",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_tokens = torch.tensor([[-1.0720, -0.5001], [-0.0020, -0.4311], [-0.0020, -0.4311] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1fd4b6-d734-4769-bf90-9219170b6747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0720, -0.5001],\n",
       "        [-0.0020, -0.4311],\n",
       "        [-0.0020, -0.4311]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765fcc5-68d0-40af-940f-ca4df8e1d7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7023e59-e47e-4011-b294-fbe1b438967b",
   "metadata": {},
   "source": [
    "As the next step, let's create the Q,K,V matrices. This is done by transforming our embedding matrix using three weight vectors. WQ, WK and WV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aff325-6ca7-4d62-972a-7184c34cfce3",
   "metadata": {},
   "source": [
    "let's cosinder the following WQ, WK and WV matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea2dcd5-ab1a-47de-93f1-94e0892401d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WQ = torch.tensor([[-0.0271, -0.3840],\n",
    "        [-0.3940, -0.6610]]).requires_grad_(True)\n",
    "\n",
    "WK = torch.tensor([[-0.4109,  0.5777],\n",
    "        [-0.1162, -0.1661]]).requires_grad_(True)\n",
    "\n",
    "WV = torch.tensor([[-0.2045,  0.1210],\n",
    "        [-0.1712, -0.4462]]).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77a2a9-af6c-4510-8b14-06938ce4a320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4af20efa-8a2d-4305-b4eb-e2bc3c7b9653",
   "metadata": {},
   "source": [
    "Now, let's transform our embedded tokens using the transformation matrices WQ, WK and WV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9e25da-d436-40da-b0d6-644991d6e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = embedded_tokens @ WQ\n",
    "K = embedded_tokens @ WK\n",
    "V = embedded_tokens @ WV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32fc41a5-2b0c-4a22-b9e6-95f7f4e33a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2261, 0.7422],\n",
       "        [0.1699, 0.2857],\n",
       "        [0.1699, 0.2857]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffaf9dd2-1980-417f-82cf-dda918a5f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4986, -0.5362],\n",
       "        [ 0.0509,  0.0705],\n",
       "        [ 0.0509,  0.0705]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad769b3-08c1-4137-b09b-32ba3cf25317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3048, 0.0934],\n",
       "        [0.0742, 0.1921],\n",
       "        [0.0742, 0.1921]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4693965",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = Q.size()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487593c-350e-4822-b775-de9da1ae450d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "120eb74c-7034-4854-93a1-37c56bcfabc3",
   "metadata": {},
   "source": [
    "$$ Q = \\begin{bmatrix} Q_{1,1} & Q_{1,2} \\\\ Q_{2,1} & Q_{2,2} \\\\ Q_{3,1} & Q_{3,2} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97773379-37de-477f-b75a-973c03617aed",
   "metadata": {},
   "source": [
    "$$ Q = \\begin{bmatrix} \\vec{Q_{1}} \\\\ \\vec{Q_{2}} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be5011c-5842-4b69-929c-c5478b1a2035",
   "metadata": {},
   "source": [
    "$$ K = \\begin{bmatrix} K_{1,1} & K_{1,2} \\\\ K_{2,1} & K_{2,2} \\\\ K_{3,1} & K_{3,2} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16658adc-c4d0-4c0d-b130-f1008f9865d7",
   "metadata": {},
   "source": [
    "$$ K^{T} = \\begin{bmatrix} \\vec{K_{1}} \\\\ \\vec{K_{2}} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e047c5-0ccc-4242-b25d-970a11f4c22c",
   "metadata": {},
   "source": [
    "$$ K^{T} = \\begin{bmatrix} K_{1,1} & K_{2,1} \\\\ K_{1,2} & K_{2,2} \\\\ K_{1,3} & K_{2,3} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20eb10-10a8-4dc1-93a0-8620d2fe46b4",
   "metadata": {},
   "source": [
    "<!-- $$ K = \\begin{bmatrix} \\vec{K_{1}} \\\\ \\vec{K_{2}} \\\\ \\vec{K_{3}} \\end{bmatrix}$$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdba19-c34b-481e-9cf3-04c9292f07c2",
   "metadata": {},
   "source": [
    "$$ V = \\begin{bmatrix} V_{1,1} & V_{1,2} \\\\ V_{2,1} & V_{2,2}  \\\\ V_{3,1} & V_{3,2} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2f239-ca78-4b0c-9aec-3ec0f65370c9",
   "metadata": {},
   "source": [
    "Attention logits are given by $QK^{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269fc364-8c22-4217-8957-702600226885",
   "metadata": {},
   "source": [
    "$$ QK^{T} = \\begin{bmatrix} Q_{1,1}\\times K_{1,1} + Q_{1,2}\\times K_{1,2} &\n",
    "Q_{1,1}\\times K_{2,1} + Q_{1,2}\\times K_{2,2} & \n",
    "Q_{1,1}\\times K_{3,1} + Q_{1,2}\\times K_{3,2} \\\\ \n",
    "Q_{2,1}\\times K_{1,1} + Q_{2,2}\\times K_{1,2} & \n",
    "Q_{2,1}\\times K_{2,1} + Q_{2,2}\\times K_{2,2} & \n",
    "Q_{2,1}\\times K_{3,1} + Q_{2,2}\\times K_{3,2} \\\\\n",
    "Q_{3,1}\\times K_{1,1} + Q_{3,2}\\times K_{1,2} & \n",
    "Q_{3,1}\\times K_{2,1} + Q_{3,2}\\times K_{2,2} & \n",
    "Q_{3,1}\\times K_{3,1} + Q_{3,2}\\times K_{3,2} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c42922-0432-412b-93ac-184cc31ecfdb",
   "metadata": {},
   "source": [
    "Equivalently,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4f5b9-a138-4438-b819-b25680a8f313",
   "metadata": {},
   "source": [
    "$$ QK^{T} = \\begin{bmatrix} \\vec{Q_{1}}\\cdot \\vec{K_{1}} & \n",
    "\\vec{Q_{1}}\\cdot \\vec{K_{2}} & \n",
    "\\vec{Q_{1}}\\cdot \\vec{K_{3}} \\\\ \n",
    "\\vec{Q_{2}}\\cdot \\vec{K_{1}} & \n",
    "\\vec{Q_{2}}\\cdot \\vec{K_{2}} & \n",
    "\\vec{Q_{2}}\\cdot \\vec{K_{3}} \\\\\n",
    "\\vec{Q_{3}}\\cdot \\vec{K_{1}} & \n",
    "\\vec{Q_{3}}\\cdot \\vec{K_{2}} & \n",
    "\\vec{Q_{3}}\\cdot \\vec{K_{3}} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03f96b33-4adc-48c0-983f-c47f3a67ac9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2853,  0.0638,  0.0638],\n",
       "        [-0.0685,  0.0288,  0.0288],\n",
       "        [-0.0685,  0.0288,  0.0288]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_logits = torch.matmul(Q, K.T)\n",
    "attn_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e367763-2d13-4ea8-b427-56b67c2b8d3c",
   "metadata": {},
   "source": [
    "what is $\\vec{Q_{1}}$? It is a representation of the $1^{st}$ token. <br>\n",
    "what is K1? It is another representation of the $1^{st}$ token. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc0918-a73d-4b51-b731-4b7c469b706d",
   "metadata": {},
   "source": [
    "Each element in the `attn_logits` matrix is a measure of how similar two $\\vec{Q}$ and $\\vec{K}$ vectors are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182962a-a37c-42b6-8ba5-660d07d1f658",
   "metadata": {},
   "source": [
    "Each row of the `attn_logits` matrix shows how similar a query to all the keys. For example, row 1 is (similarity between Q1 and K1, similarity between Q1 and K2, similarity between Q1 and K3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67822f3c-4f04-4475-b118-af876228d941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe25f7f6-abc5-4dee-8bec-089995d38f16",
   "metadata": {},
   "source": [
    "The next step is scaling the `attention_logits` matrix with the scaling factor, $\\sqrt(d_{k}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dec1b8-212c-440c-b8cc-29fc565370ec",
   "metadata": {},
   "source": [
    "$$ QK^{T}/\\sqrt(d_{k}) = \\begin{bmatrix} \\frac{\\vec{Q_{1}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})} & \n",
    "\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{2}}}{ \\sqrt(d_{k}) } & \n",
    "\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{3}}}{ \\sqrt(d_{k}) } \\\\ \n",
    "\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{1}}}{ \\sqrt(d_{k}) } & \n",
    "\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{2}}}{ \\sqrt(d_{k}) } & \n",
    "\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{3}}}{ \\sqrt(d_{k}) } \\\\\n",
    "\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{1}}}{ \\sqrt(d_{k}) } & \n",
    "\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{2}}}{ \\sqrt(d_{k}) } & \n",
    "\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{3}}}{ \\sqrt(d_{k}) } \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28f7d892-414f-4d6a-b189-c380fb49c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_attention_logits = torch.matmul(Q, K.T)/ math.sqrt(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61cc140c-e29b-4449-9ffb-1eda8a23c0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2017,  0.0451,  0.0451],\n",
       "        [-0.0484,  0.0204,  0.0204],\n",
       "        [-0.0484,  0.0204,  0.0204]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_attention_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b433e76-5f77-4695-a90f-031509b19c78",
   "metadata": {},
   "source": [
    "Finally, we apply the softmax operation to each row. This normalizes the values of each row so that the sum of these values is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e6192-6540-48a8-aec8-a0c60d88e86e",
   "metadata": {},
   "source": [
    "$$ softmax(QK^{T}/\\sqrt(d_{k})) = \\begin{bmatrix} \\frac{exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) }{ exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}})} & \n",
    "\\frac{exp(\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{2}}}{ \\sqrt(d_{k}) })}{ exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}})  } & \n",
    "\\frac{exp(\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{3}}}{ \\sqrt(d_{k}) })}{ exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{1}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}}) } \\\\ \n",
    "\\frac{exp(\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{1}}}{ \\sqrt(d_{k}) })}{ exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}}) } & \n",
    "\\frac{exp(\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{2}}}{ \\sqrt(d_{k}) })}{ exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}}) } & \n",
    "\\frac{exp(\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{3}}}{ \\sqrt(d_{k}) })}{ exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{2}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}}) } \\\\\n",
    "\\frac{exp(\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{1}}}{ \\sqrt(d_{k}) })}{  exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}}) } & \n",
    "\\frac{exp(\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{2}}}{ \\sqrt(d_{k}) })}{ exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}}) } & \n",
    "\\frac{exp(\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{3}}}{ \\sqrt(d_{k}) })}{ exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{1}}}{\\sqrt(d_{k})}}) + exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{2}}}{\\sqrt(d_{k})}}) + \\exp({\\frac{\\vec{Q_{3}}\\cdot \\vec{K_{3}}}{\\sqrt(d_{k})}})  } \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fd5a91f-5c31-4661-8717-1cdd3e1671cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = F.softmax(scaled_attention_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61cb7e78-2659-4051-84c9-8c5423792360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2809, 0.3595, 0.3595],\n",
       "        [0.3182, 0.3409, 0.3409],\n",
       "        [0.3182, 0.3409, 0.3409]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c54673-add7-4173-877f-c25dccc60ffa",
   "metadata": {},
   "source": [
    "Note that values in each row add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fadaa733-3243-4fd9-96e1-2c9dd87b2e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88e27a7d-731b-41a2-8131-0ba7d38e3dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights[1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "541bcdd1-9ada-4c84-8f94-5047f7fac678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights[2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a73461-0d80-47a4-a860-928377bf4800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6731b50-f544-483d-bfd8-c6be7d4f08fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af3135b-4a41-47cf-b1e7-970dc33d9907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1390, 0.1644],\n",
       "        [0.1476, 0.1607],\n",
       "        [0.1476, 0.1607]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights @ V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6fedd-047e-4a06-99d0-c970c467dee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eeb5be6-c62f-41d1-a150-7cb55998d07b",
   "metadata": {},
   "source": [
    "output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e23898a-08f7-41e4-9b6e-fc925ff0d594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1390, 0.1644],\n",
       "        [0.1476, 0.1607],\n",
       "        [0.1476, 0.1607]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(attention_weights, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f8d3c-de6a-47e7-aa86-23b6518d1623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d4f80-d82d-4b94-add9-3429603edf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
