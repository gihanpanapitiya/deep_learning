

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Graph Convolutional Networks &mdash; deep learning .1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=a6a68382" />
      <link rel="stylesheet" type="text/css" href="../../../_static/fonts.css?v=5583d106" />
      <link rel="stylesheet" type="text/css" href="../../../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=69a67b7f"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link href="../../../_static/style.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            deep learning
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">GNNs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/gnns/gcn.html">Graph Convolutional Networks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Transformers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/transformers/attention_1.html">Self Attention - Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/transformers/attention_2.html">Self Attention - Another implementation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">deep learning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Graph Convolutional Networks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/docs/tutorials/gnns/gcn.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Graph-Convolutional-Networks">
<h1>Graph Convolutional Networks<a class="headerlink" href="#Graph-Convolutional-Networks" title="Link to this heading"></a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch_geometric.utils</span> <span class="kn">import</span> <span class="n">dense_to_sparse</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Linear</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn</span> <span class="kn">import</span> <span class="n">MessagePassing</span>
<span class="kn">from</span> <span class="nn">torch_geometric.utils</span> <span class="kn">import</span> <span class="n">add_self_loops</span><span class="p">,</span> <span class="n">degree</span>
</pre></div>
</div>
</div>
<p>Let’s build a graph convolutional neural network. I will use the definition of a GCN layer given in the torch_geometric dicumentation.</p>
<p><span class="math notranslate nohighlight">\(x_{i}^{(k)} = \sum_{j \in N(i) \bigcup i} \frac{1}{\sqrt(deg(i))\cdot\sqrt(deg(j)) } \cdot (W^{T} \cdot x_{j}^{(k-1)})+b\)</span></p>
<p><span class="math notranslate nohighlight">\(x\)</span> are node features. <span class="math notranslate nohighlight">\(N(i)\)</span> are the neighbors of node <span class="math notranslate nohighlight">\(i\)</span> <span class="math notranslate nohighlight">\(deg(i)\)</span> and <span class="math notranslate nohighlight">\(deg(j)\)</span> are the degrees of nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. The degree refers to the number of edges attached to a given node. <span class="math notranslate nohighlight">\(W\)</span> is a matrix that transforms the node features. The elements of this matrix are trainable. <span class="math notranslate nohighlight">\(b\)</span> is a bias value.</p>
<p>Here, k is used to denote the graph convolution layer. This can be identified as a single pass through the graph convolution operation. In other words, a single iteration of using the above equation on the current set of node (and/or edge) features.</p>
<p>Let’s understand what happens here. In this equation, we update the the node features of node <span class="math notranslate nohighlight">\(i\)</span>. The subscript of the summation symbol indicates that we consider the neighbors of node <span class="math notranslate nohighlight">\(i\)</span> and node <span class="math notranslate nohighlight">\(i\)</span> itself. For a given neighbor <span class="math notranslate nohighlight">\(j\)</span>, we transform it’s node feature <span class="math notranslate nohighlight">\(x_{j}\)</span> using the weight matrix <span class="math notranslate nohighlight">\(W\)</span>. We divide this value by the product of the square root of the degrees of nodes <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p>We do this operation for all the neighboring nodes of <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>Then we collect all these transformed node features of the neighbhring nodes corresponding to node <span class="math notranslate nohighlight">\(i\)</span> and add them all together. Optionally, we can add a bias term <span class="math notranslate nohighlight">\(b\)</span> to this summation. This summation becomes the new node feature of node <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(x_{i}^{k}\)</span> at iteration <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p><img alt="title" src="docs/tutorials/gnns/assets/gcn1.png" /></p>
<p>Now let’s build graph convolution nework using torch_geometric. This implementation is based on the code segment provided in their documentation. I did some modifications to make it easy to compare with another implementaion. Specifically I removed <code class="docutils literal notranslate"><span class="pre">self.lin.reset_parameters()</span></code> and added my own weight matrx <span class="math notranslate nohighlight">\(W\)</span>, and set the bias values to zero.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GCNConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">weight_data</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s1">&#39;add&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">weight_data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">out_channels</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># line 1</span>

        <span class="n">source</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">edge_index</span> <span class="c1"># line 2</span>
        <span class="n">deg</span> <span class="o">=</span> <span class="n">degree</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="c1"># line 3</span>

        <span class="n">deg_inv_sqrt</span> <span class="o">=</span> <span class="n">deg</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> <span class="c1"># line 4</span>

        <span class="c1"># if the inverse square root is infinity, that value is set to zero.</span>
        <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">deg_inv_sqrt</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># line 5</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">source</span><span class="p">]</span> <span class="o">*</span> <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">target</span><span class="p">]</span> <span class="c1"># line 6</span>
        <span class="c1"># print(norm)</span>

        <span class="c1"># propagate is a method implemented in MessagePassing. This is where</span>
        <span class="c1"># massage passing takes place. you have to send the edge indices and the node features.</span>
        <span class="c1"># additionally, you can send other optional values to create your message from node j to node i.</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span> <span class="c1"># line 7</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="c1"># line 8</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_j</span><span class="p">,</span> <span class="n">norm</span><span class="p">):</span>
        <span class="c1"># this is wehere we define the message from node j to node i.</span>
        <span class="c1"># print(x_j)</span>
        <span class="k">return</span> <span class="n">norm</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_j</span>
</pre></div>
</div>
</div>
<section id="Let's-understand-what-happens-at-each-line-of-the-forward-method.">
<h2>Let’s understand what happens at each line of the forward method.<a class="headerlink" href="#Let's-understand-what-happens-at-each-line-of-the-forward-method." title="Link to this heading"></a></h2>
<p>line 1: We transform the input features using the W matrix and a bias term. This corresponds to the <span class="math notranslate nohighlight">\((W^{T} \cdot x_{j}^{(k-1)})+b\)</span> part in our equation for <span class="math notranslate nohighlight">\(x_{i}^{(k)}\)</span></p>
<p>line 2: We seperate the two lists of connected nodes to two lists, <span class="math notranslate nohighlight">\(row\)</span> and <span class="math notranslate nohighlight">\(col\)</span>.</p>
<p>line 3: we calculate the degree of each node. We use pytoorch_geometrics, <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/2.4.0/_modules/torch_geometric/utils/degree.html">degree function</a>. The first argument to the degree function is the vector of edge indices. The second argument is the number of nodes in the graph.</p>
<p>line 4: Take the square root of the degree values.</p>
<p>line 5: if the inverse square root is infinity, that value is set to zero.</p>
<p>line 6: This is where we calculate the factor <span class="math notranslate nohighlight">\(\frac{1}{\sqrt(deg(i))\cdot\sqrt(deg(j)) }\)</span>.</p>
<p>line 7: This is the confusing step in building GNNs using pytorch geometric. <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/2.4.0/_modules/torch_geometric/nn/conv/message_passing.html#MessagePassing.propagate">propagate</a> method is where the MessagePassing happens. You have to send the edge_index and other additional values that are needed to contstruct the message. How to construct the message is defined in the <code class="docutils literal notranslate"><span class="pre">message</span></code> function. In our case, the message that is passed to the target node is
constructed by multiplying the source node’s features with the nomalization factor. Once the messages are constructed at each source node, they are aggregated. In our case, the aggreegation is the summing of all the neighbouring source node features. This aggregation operation also takes place inside the <code class="docutils literal notranslate"><span class="pre">propagate</span></code> method.</p>
<p>Note that in our case, the the neighbouring nodes of a given target node consists of the target node itself. This is becasue we consider self loops. Self loops are the edges that connect a node to itself.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">flow</span></code> parameter in the <code class="docutils literal notranslate"><span class="pre">MessagePassing</span></code> class determines the from where to where the messages are sent. By default, the value of <code class="docutils literal notranslate"><span class="pre">flow</span></code> is “source_to_target”. If the edge index is a tensor of the shape, 2 <span class="math notranslate nohighlight">\(\times\)</span> ‘number of messages’ (as in our case). The messages are sent from nodes given in the first list of the <code class="docutils literal notranslate"><span class="pre">edge_index</span></code> tensor to the second index of the <code class="docutils literal notranslate"><span class="pre">edge_index</span></code> tensor. That is, the source nodes are in the first list of the edge_index tensor. The target nodes are
in the second list of of the edge_index tensor.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
<section id="Define-the-node-and-edge-features">
<h3>Define the node and edge features<a class="headerlink" href="#Define-the-node-and-edge-features" title="Link to this heading"></a></h3>
<p>These are our node features. Node 0 is featurized with <span class="math notranslate nohighlight">\([0, 1]\)</span>. Node 1 is featurized with <span class="math notranslate nohighlight">\([2, 3]\)</span>. Node 2 is featurized with <span class="math notranslate nohighlight">\([4, 5]\)</span>. Node 3 is featurized with <span class="math notranslate nohighlight">\([6, 7]\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">node_feats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">],</span>
         <span class="p">[</span><span class="mf">6.</span><span class="p">,</span> <span class="mf">7.</span><span class="p">]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The following matrix indicates which two nodes are connected. That is if node <span class="math notranslate nohighlight">\(i, j\)</span> are connected with an edge the <span class="math notranslate nohighlight">\(i, j\)</span> element of the following matrix is 1.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adj_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                            <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                            <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]])</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">weight</span> <span class="pre">data</span></code> is the <span class="math notranslate nohighlight">\(W\)</span> matrix that transforms our node features.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weight_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<p>pytorch_geometric requires that adjacency matrix expressed as a two lists. <span class="math notranslate nohighlight">\(i^{th}\)</span> elements of the two lists are the node indices that are connected.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">dense_to_sparse</span><span class="p">(</span><span class="n">adj_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">edge_index</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[0, 0, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3],
        [0, 1, 0, 1, 2, 3, 1, 2, 3, 1, 2, 3]])
</pre></div></div>
</div>
<p>Let’s just see how the degree values are calcualted.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">source</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">edge_index</span> <span class="c1"># line 2</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([0, 1, 0, 1, 2, 3, 1, 2, 3, 1, 2, 3])
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deg</span> <span class="o">=</span> <span class="n">degree</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># line 3</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">deg</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([2., 4., 3., 3.])
</pre></div></div>
</div>
<p>Now, let’s create the convolution layer.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conv</span> <span class="o">=</span> <span class="n">GCNConv</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">weight_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output_node_features</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">node_feats</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output_node_features</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[[0.7071, 1.5607],
         [3.3868, 4.5677],
         [3.9107, 4.8660],
         [3.9107, 4.8660]]], grad_fn=&lt;AddBackward0&gt;)
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Gihan.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>